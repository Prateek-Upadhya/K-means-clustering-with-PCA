{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "v-PsduPpBasQ"
      },
      "outputs": [],
      "source": [
        "#Imports \n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy import sparse\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The paper did not mention how they have calculated their clustering accuracy. Hence we decided to use this function from scikit-learn.\n",
        "- All these clustering evaluation metrics have a maximum value of 1.0 - hence higher the value the better\n"
      ],
      "metadata": {
        "id": "OA3bau2FFGVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from sklearn import metrics\n",
        "from time import time\n",
        "\n",
        "evaluations = []\n",
        "evaluations_std = []\n",
        "\n",
        "\n",
        "def fit_and_evaluate(km, X, name=None, n_runs=5):\n",
        "    name = km.__class__.__name__ if name is None else name\n",
        "\n",
        "    train_times = []\n",
        "    scores = defaultdict(list)\n",
        "    for seed in range(n_runs):\n",
        "        km.set_params(random_state=seed)\n",
        "        t0 = time()\n",
        "        km.fit(X)\n",
        "        train_times.append(time() - t0)\n",
        "        scores[\"Homogeneity\"].append(metrics.homogeneity_score(labels, km.labels_))\n",
        "        scores[\"Completeness\"].append(metrics.completeness_score(labels, km.labels_))\n",
        "        scores[\"V-measure\"].append(metrics.v_measure_score(labels, km.labels_))\n",
        "        scores[\"Adjusted Rand-Index\"].append(\n",
        "            metrics.adjusted_rand_score(labels, km.labels_)\n",
        "        )\n",
        "        scores[\"Silhouette Coefficient\"].append(\n",
        "            metrics.silhouette_score(X, km.labels_, sample_size=2000)\n",
        "        )\n",
        "    train_times = np.asarray(train_times)\n",
        "\n",
        "    print(f\"clustering done in {train_times.mean():.2f} ± {train_times.std():.2f} s \")\n",
        "    evaluation = {\n",
        "        \"estimator\": name,\n",
        "        \"train_time\": train_times.mean(),\n",
        "    }\n",
        "    evaluation_std = {\n",
        "        \"estimator\": name,\n",
        "        \"train_time\": train_times.std(),\n",
        "    }\n",
        "    for score_name, score_values in scores.items():\n",
        "        mean_score, std_score = np.mean(score_values), np.std(score_values)\n",
        "        print(f\"{score_name}: {mean_score:.3f} ± {std_score:.3f}\")\n",
        "        evaluation[score_name] = mean_score\n",
        "        evaluation_std[score_name] = std_score\n",
        "    evaluations.append(evaluation)\n",
        "    evaluations_std.append(evaluation_std)"
      ],
      "metadata": {
        "id": "GKvT5_fxBsV4"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This function is used to sample documenst from the corpus to create the desired dataset"
      ],
      "metadata": {
        "id": "im2l-KCaLqBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_docs(dataset, doc_num, curr_file_nums):\n",
        "  final_data = []\n",
        "  target_vals = []\n",
        "  while(curr_file_nums != doc_num):\n",
        "    for i in range(len(dataset.target)):\n",
        "      if(curr_file_nums[dataset.target[i]] < doc_num[dataset.target[i]]):\n",
        "        curr_file_nums[dataset.target[i]] = curr_file_nums[dataset.target[i]] + 1\n",
        "        final_data.append(dataset.data[i])\n",
        "        target_vals.append(dataset.target[i])\n",
        "        \n",
        "  return final_data, target_vals"
      ],
      "metadata": {
        "id": "aD5dwHrdzA5f"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Objective of this experiment: \n",
        "- In the paper they prove that performing k-means clustering in Principal component subspace helps improve clustering accuracy.\n",
        "\n",
        "- It shows that PCA is actually beneficial for K means clustering \n",
        "\n",
        "`performing the same experimanet on 60 datasets becomes repetitive - hence we have shown these results on A5(balanced and A5(unbalanced) datasets`"
      ],
      "metadata": {
        "id": "B8H1mEmAG0d9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\n",
        "    \"comp.graphics\",\n",
        "    \"rec.motorcycles\",\n",
        "    \"rec.sport.baseball\",\n",
        "    \"sci.space\",\n",
        "    \"talk.politics.mideast\"\n",
        "]\n",
        "\n",
        "dataset = fetch_20newsgroups(\n",
        "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
        "    subset=\"all\",\n",
        "    categories = categories,\n",
        "    shuffle = True,\n",
        "    random_state = 42,\n",
        ")\n",
        "\n",
        "print(f\"the datatype of dataset is{type(dataset)} and it contains the following attributes {dataset.keys()}\")\n",
        "labels = dataset.target\n",
        "unique_labels = np.unique(dataset.target)\n",
        "true_k = unique_labels.shape[0]\n",
        "\n",
        "print(f\"We found {len(dataset.data)} documents - belonging to the {true_k} specified categories namely {dataset.target_names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4Huqe1AEdTY",
        "outputId": "3d30aebe-a94c-491f-b18b-c56c083003e6"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the datatype of dataset is<class 'sklearn.utils.Bunch'> and it contains the following attributes dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n",
            "We found 4890 documents - belonging to the 5 specified categories namely ['comp.graphics', 'rec.motorcycles', 'rec.sport.baseball', 'sci.space', 'talk.politics.mideast']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(dataset.target)\n",
        "unique, counts = np.unique(dataset.target, return_counts=True)\n",
        "\n",
        "doc_freq = dict(zip(unique, counts))\n",
        "doc_freq\n",
        "\n",
        "print(f\"Number of documents belonging to {dataset.target_names[0]}: {doc_freq[0]}\")\n",
        "print(f\"Number of documents belonging to {dataset.target_names[1]}: {doc_freq[1]}\") \n",
        "print(f\"Number of documents belonging to {dataset.target_names[2]}: {doc_freq[2]}\") \n",
        "print(f\"Number of documents belonging to {dataset.target_names[3]}: {doc_freq[3]}\") \n",
        "print(f\"Number of documents belonging to {dataset.target_names[4]}: {doc_freq[4]}\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F3wmKIZkO4A",
        "outputId": "c97a8252-901a-4439-c4ca-747402d3dc48"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents belonging to comp.graphics: 973\n",
            "Number of documents belonging to rec.motorcycles: 996\n",
            "Number of documents belonging to rec.sport.baseball: 994\n",
            "Number of documents belonging to sci.space: 987\n",
            "Number of documents belonging to talk.politics.mideast: 940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "jU6ZEf16yOcA",
        "outputId": "8f21d68c-a326-4c6b-ac21-831259cd6152"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nFirst, you seem to assume all atheists think alike.  An atheist does not\\nbelieve in the existence of a god.  Our opinions on issues such as \\ncapital punishment and abortion, however, vary greatly.  \\n\\nIf you were attacking the views of a particular atheist (Benedikt, I \\npresume), then please present your argument as such and do not lump us\\nall together.\\n\\nAs for the issues, let\\'s start with abortion.  Personally, I do not support\\nabortion as a means of population control or contraception-after-the-fact.\\nHowever, I support the right of any woman to have an abortion, regardless\\nof what my personal views may be, because it would be arrogant of me to tell\\nany individual what he/she may or may not do to his/her body, and the domain\\nof legislators should not extend into the uterus.  That\\'s my opinion, and I\\nam sure many atheists and theists would disagree with me.\\n\\nI do not defend homosexuality as a means of population control, but I \\ncertainly defend it as an end to itself.  I think most homosexuals would\\nbe angered to hear of anyone characterizing their personal relationship as\\nnothing more than a conscious effort to keep population levels down.  \\n\\nAs for atheists believing all values are biological, I have no idea what\\nyou\\'re talking about.\\n\\nFinally, there are the issues of war and capital punishment.  An atheist\\ncan object to either one just as easily as a theist might.  You seem to\\nbe hung up on some supposed conspiratorial link between atheism and \\npopulation control.  Could this be the \"atheist cause\" you were referring \\nto a few posts back?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------\n",
        "#Balanced A5 dataset\n",
        "\n",
        "Sample equal number of documents from the dataset (100 in this case)"
      ],
      "metadata": {
        "id": "Rd-73RSwMymv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(A5_dataset_bal, labels) = sample_docs(dataset, [100,100,100,100,100], [0,0,0,0,0])"
      ],
      "metadata": {
        "id": "hpXxske81EUw"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_df=0.5,\n",
        "    min_df=5,\n",
        "    stop_words=\"english\",\n",
        "    max_features=1000\n",
        ")\n",
        "X_tfidf = vectorizer.fit_transform(A5_dataset_bal)\n",
        "\n",
        "print(f\"n_samples: {X_tfidf.shape[0]}, n_features: {X_tfidf.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oBNLpB3EhEO",
        "outputId": "8fe11564-9cc5-4c85-fbb3-3a07b3bf209c"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_samples: 500, n_features: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There exists an issue with scikit-learn pca implementation which requires the input to be a dense matrix. This is problematic for us as TfidfVectorizer returns a sparse result\n",
        "\n",
        "- following some of the comments in this github page, we decided to centre the data and then apply truncated SVD which achieves a similar result as PCA.\n",
        "\n",
        "the issue: https://github.com/scikit-learn/scikit-learn/issues/12794 "
      ],
      "metadata": {
        "id": "lz1asti4idt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "def dim_reduction_pca(TFIDF, final_dim):\n",
        "  \n",
        "  #very important\n",
        "  temp = TFIDF.toarray()\n",
        "  mean = temp.mean(axis = 0)\n",
        "  centered_tfidf = temp - mean\n",
        "\n",
        "  pca = make_pipeline(TruncatedSVD(n_components=100), Normalizer(copy=False))\n",
        "  new_tfidf = pca.fit_transform(centered_tfidf)\n",
        "  return new_tfidf"
      ],
      "metadata": {
        "id": "Mcc-p7qdXhhv"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUAMcYXl_NPC",
        "outputId": "98ce2cc2-a760-4fee-a385-c4563dcbd3ed"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(\n",
        "    n_clusters = 5,\n",
        "    max_iter = 20,\n",
        "    n_init = 5,\n",
        ")\n",
        "print(f\"K means clustering with {X_tfidf.shape[1]} words\")\n",
        "fit_and_evaluate(kmeans, X_tfidf, name=\"KMeans\\non tf-idf vectors\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKd9dvUXEoNu",
        "outputId": "f2cb87d9-354c-48c9-e773-4f0b9f2db4ef"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K means clustering with 1000 words\n",
            "clustering done in 0.07 ± 0.01 s \n",
            "Homogeneity: 0.313 ± 0.066\n",
            "Completeness: 0.359 ± 0.074\n",
            "V-measure: 0.334 ± 0.069\n",
            "Adjusted Rand-Index: 0.219 ± 0.059\n",
            "Silhouette Coefficient: 0.009 ± 0.004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dimension reduction\n",
        "new_tfidf = dim_reduction_pca(X_tfidf, 100)"
      ],
      "metadata": {
        "id": "Tp7Mpf0-8iqI"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(\n",
        "    n_clusters= 5,\n",
        "    max_iter = 20,\n",
        "    n_init = 10,\n",
        ")\n",
        "print(f\"K means clustering with {new_tfidf.shape[1]} words After PCA\")\n",
        "fit_and_evaluate(kmeans, new_tfidf, name=\"KMeans\\non tf-idf vectors\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nL0xOhlYcOw",
        "outputId": "38a6972d-a946-46c4-9872-2c55b27e7f32"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K means clustering with 100 words After PCA\n",
            "clustering done in 0.37 ± 0.08 s \n",
            "Homogeneity: 0.381 ± 0.037\n",
            "Completeness: 0.454 ± 0.035\n",
            "V-measure: 0.414 ± 0.037\n",
            "Adjusted Rand-Index: 0.328 ± 0.035\n",
            "Silhouette Coefficient: 0.036 ± 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`It is clearly seen that there is an increase in the clustering accuracy `"
      ],
      "metadata": {
        "id": "ftp_6JpPNkcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------\n",
        "#Unbalanced A5 dataset\n",
        "\n",
        "Sample unequal number of documents from the dataset for each news group"
      ],
      "metadata": {
        "id": "l-HAglL7NuIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(A5_dataset_unbal, labels) = sample_docs(dataset, [200,140,120,100,60], [0,0,0,0,0])"
      ],
      "metadata": {
        "id": "dRetYb756-Ed"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_df=0.5,\n",
        "    min_df=5,\n",
        "    stop_words=\"english\",\n",
        "    max_features=1000\n",
        ")\n",
        "X_tfidf = vectorizer.fit_transform(A5_dataset_unbal)\n",
        "\n",
        "print(f\"n_samples: {X_tfidf.shape[0]}, n_features: {X_tfidf.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmGfLht6P8R1",
        "outputId": "50e1c716-4930-4dd9-fbc2-f20c4caab828"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_samples: 620, n_features: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2Axp7HfQINg",
        "outputId": "4941d0fe-74e6-425c-d7e0-2db77f10d04c"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(620, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(\n",
        "    n_clusters = 5,\n",
        "    max_iter = 20,\n",
        "    n_init = 5,\n",
        ")\n",
        "print(f\"K means clustering with {X_tfidf.shape[1]} words\")\n",
        "fit_and_evaluate(kmeans, X_tfidf, name=\"KMeans\\non tf-idf vectors\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ECArSf3QLWb",
        "outputId": "14307dde-3cba-4e8a-8359-67d169224525"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K means clustering with 1000 words\n",
            "clustering done in 0.08 ± 0.02 s \n",
            "Homogeneity: 0.298 ± 0.049\n",
            "Completeness: 0.307 ± 0.040\n",
            "V-measure: 0.302 ± 0.044\n",
            "Adjusted Rand-Index: 0.224 ± 0.063\n",
            "Silhouette Coefficient: 0.005 ± 0.003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dimension reduction\n",
        "new_tfidf = dim_reduction_pca(X_tfidf, 100)"
      ],
      "metadata": {
        "id": "qiRMxoxZQQDC"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(\n",
        "    n_clusters= 5,\n",
        "    max_iter = 20,\n",
        "    n_init = 10,\n",
        ")\n",
        "print(f\"K means clustering with {new_tfidf.shape[1]} words After PCA\")\n",
        "fit_and_evaluate(kmeans, new_tfidf, name=\"KMeans\\non tf-idf vectors\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYe0cSBxQTHo",
        "outputId": "a372b1cb-7f32-400c-f585-949261b2424d"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K means clustering with 100 words After PCA\n",
            "clustering done in 0.53 ± 0.15 s \n",
            "Homogeneity: 0.369 ± 0.053\n",
            "Completeness: 0.404 ± 0.063\n",
            "V-measure: 0.386 ± 0.058\n",
            "Adjusted Rand-Index: 0.312 ± 0.047\n",
            "Silhouette Coefficient: 0.032 ± 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Once again the clustering accuracy is shown to increase`"
      ],
      "metadata": {
        "id": "yIhpNf55QYoH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w9jC0e1bQd78"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}